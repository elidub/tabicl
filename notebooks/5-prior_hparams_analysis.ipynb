{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3415969",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Literal, Dict, Any, Tuple\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from itertools import product, combinations\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pgmpy.models.MarkovNetwork import MarkovNetwork\n",
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "\n",
    "from tabicl.prior.dataset import PriorDataset\n",
    "\n",
    "from gtfm.graph.scm import get_graph\n",
    "from gtfm.viz.graph import draw_scms\n",
    "from gtfm.graph.moral_marg import old_check\n",
    "from gtfm.utils.adj import remove_axis\n",
    "from gtfm.viz.imshow import imshow\n",
    "from gtfm.prior.hparams import set_scm_hparams, PriorConfig\n",
    "from gtfm.utils.misc import clipboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b215085",
   "metadata": {},
   "source": [
    "### Visaluze graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1957bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prior_data(prior_config: PriorConfig):\n",
    "    dataset = PriorDataset(**prior_config.to_dict())\n",
    "    xs, ys, ds, seq_lens, train_sizes, adjs, priors = dataset.prior.get_batch()\n",
    "    (\n",
    "        graphs_full, \n",
    "        graphs_moma, \n",
    "        graphs_lean_moma,\n",
    "        \n",
    "        nodelists,\n",
    "        densities,\n",
    "    ) = map(list, zip(*[(\n",
    "        prior.graph_full, \n",
    "        prior.graph_moma, \n",
    "        prior.graph_lean_moma,\n",
    "        \n",
    "        prior.graph_full.graph['nodes_include'],\n",
    "        prior.density,\n",
    "    ) for prior in priors]))\n",
    "\n",
    "    n_graphs = len(graphs_full)\n",
    "\n",
    "    prior_config.priors = priors\n",
    "    prior_config.graphs_full = graphs_full\n",
    "    prior_config.graphs_moma = graphs_moma\n",
    "    prior_config.graphs_lean_moma = graphs_lean_moma\n",
    "    prior_config.nodelists = nodelists\n",
    "    prior_config.n_graphs = n_graphs\n",
    "    prior_config.densities = densities\n",
    "\n",
    "    return prior_config, priors\n",
    "\n",
    "hidden_dims = [3, 20, 50]\n",
    "n_featureses = [5, 10, 20]\n",
    "combs = list(product(hidden_dims, n_featureses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d274525",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_infos = {}\n",
    "\n",
    "for hidden_dim, n_features in tqdm(combs):\n",
    "    prior_config = PriorConfig(\n",
    "        custom_scm_fixed_hp = {\n",
    "            'is_causal': True,\n",
    "            'in_clique': False,\n",
    "            'hidden_dim': hidden_dim,\n",
    "        },\n",
    "        min_features=n_features,\n",
    "        max_features=n_features,\n",
    "        dataset_kwargs=dict(\n",
    "            batch_size_per_gp = 1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    prior_info, _ = load_prior_data(prior_config = prior_config)\n",
    "    prior_infos[(hidden_dim, n_features)] = prior_info\n",
    "\n",
    "\n",
    "# prior_info = PriorConfig(\n",
    "#     custom_scm_fixed_hp = {\n",
    "#         'is_causal': True,\n",
    "#         'in_clique': False,\n",
    "#         'hidden_dim': 3,\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# # prior_info = load_prior_data(prior_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, 11)\n",
    "nrows, ncols = len(hidden_dims), len(n_featureses)\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(2*ncols, 2*nrows), squeeze=False, sharex =True, sharey=True)\n",
    "\n",
    "for ax, (hidden_dim, n_features) in zip(axs.flatten(), combs, strict=True):\n",
    "    prior_info = prior_infos[(hidden_dim, n_features)]\n",
    "    ax.hist(prior_info.densities, bins=bins)\n",
    "    ax.set_title(f\"{hidden_dim = }\\n{n_features = }\")\n",
    "fig.supxlabel('Density (% of possible edges)')\n",
    "fig.supylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6,4))\n",
    "# ax.hist(prior_info.densities, bins=10)\n",
    "# ax.set(\n",
    "#     title='Density of moralized and marginalized graphs',\n",
    "#     xlabel=r'Density (% of possible edges)',\n",
    "#     ylabel='Count',\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbca981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax, (hidden_dim, n_features) in zip(axs.flatten(), combs, strict=True):\n",
    "    prior_info = prior_infos[(hidden_dim, n_features)]\n",
    "    \n",
    "    random_selection = np.random.choice(prior_info.n_graphs, size=12, replace=False)\n",
    "\n",
    "    draw_scms(\n",
    "        graphs = [prior_info.graphs_full[i] for i in random_selection] + [prior_info.graphs_lean_moma[i] for i in random_selection], \n",
    "        suptitle=f\"{hidden_dim = }\\n{n_features = }\",\n",
    "        nodelists = [None for i in random_selection] + [prior_info.nodelists[i] for i in random_selection],\n",
    "        pos = ['layer' for i in random_selection] + ['circular' for i in random_selection],\n",
    "        n_rows=2,\n",
    "    )\n",
    "    \n",
    "    # draw_scms(\n",
    "    #     graphs = [prior_info.graphs_full[i] for i in random_selection], \n",
    "    #     suptitle=f\"{hidden_dim = }\\n{n_features = }\",\n",
    "    #     # nodelists = [None for i in random_selection],\n",
    "    #     # pos = 'circular',\n",
    "    # )\n",
    "\n",
    "    # draw_scms(\n",
    "    #     graphs = [prior_info.graphs_lean_moma[i] for i in random_selection], \n",
    "    #     suptitle=f\"{hidden_dim = }\\n{n_features = }\",\n",
    "    #     nodelists = [prior_info.nodelists[i] for i in random_selection],\n",
    "    #     pos = 'circular',\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0d218",
   "metadata": {},
   "source": [
    "### More analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_config = PriorConfig(\n",
    "    custom_scm_fixed_hp = dict(\n",
    "        is_causal = True,\n",
    "        in_clique = False,\n",
    "        # hidden_dim = 10,\n",
    "    ),\n",
    "    custom_scm_sampled_hp = dict(\n",
    "        # hidden_dim = {\n",
    "        #     \"distribution\": \"meta_trunc_norm_log_scaled\",\n",
    "        #     \"max_mean\": 50,\n",
    "        #     \"min_mean\": 5,\n",
    "        #     \"round\": True,\n",
    "        #     \"lower_bound\": 4,\n",
    "        # }\n",
    "    ),\n",
    "    min_features=2,\n",
    "    max_features=100,\n",
    "    dataset_kwargs=dict(\n",
    "        batch_size = 1024,\n",
    "        batch_size_per_gp = 1,\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset = PriorDataset(**prior_config.to_dict())\n",
    "*_, priors = dataset.prior.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33545c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'num_features': p.num_features,\n",
    "        'num_outputs': p.num_outputs,\n",
    "        'is_causal': p.is_causal,\n",
    "        'y_is_effect': p.y_is_effect,\n",
    "        'in_clique': p.in_clique,\n",
    "        'hidden_dim': p.hidden_dim,\n",
    "        'num_layers': p.num_layers,\n",
    "        'block_wise_dropout': p.block_wise_dropout,\n",
    "        'mlp_dropout_prob': p.mlp_dropout_prob,\n",
    "        'density': p.density\n",
    "    } \n",
    "    for p in priors\n",
    "])\n",
    "\n",
    "print(df.shape, df.dtypes, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_cols = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "constant_cols\n",
    "\n",
    "df_encoded = df_plot = df.drop(columns=constant_cols).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec99030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.pairplot(\n",
    "#     df_plot,\n",
    "#     height = 1.5,\n",
    "#     plot_kws={'alpha':0.5}\n",
    "# )\n",
    "\n",
    "g = sns.pairplot(\n",
    "    df_plot,\n",
    "    hue='density',\n",
    "    vars = df_plot.columns.tolist(),\n",
    "    diag_kind = 'hist',\n",
    "    height = 1.5,\n",
    "    plot_kws={'alpha':0.5},\n",
    "    diag_kws={'multiple': 'stack', 'linewidth': 0} \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647666e6",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Density is high when num_features is low, could be because when num_features is low, relatively many nodes are marginalized out, leading to denser graphs.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6211733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.inspection import partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b15944",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['density'])\n",
    "y = df_encoded['density']\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "r2_score_val, mse = r2_score(y, y_pred), mean_squared_error(y, y_pred)\n",
    "print(f'{r2_score_val = }, {mse = }')\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap_interaction_values = explainer.shap_interaction_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X, show=False)\n",
    "# plt.title(\"SHAP Feature Importance (Beeswarm)\")\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_interaction_values, X, show=False)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(25, 8)\n",
    "# plt.title(\"SHAP Interaction Feature Importance (Beeswarm)\")\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "cols_per_row = 3\n",
    "n_features = X.shape[1]\n",
    "n_rows = math.ceil(n_features / cols_per_row)\n",
    "\n",
    "# Create a big figure\n",
    "fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(15, 4 * n_rows))\n",
    "axes = axes.flatten() # Flatten 2D grid to 1D list for easy looping\n",
    "\n",
    "for i, col_name in enumerate(X.columns):\n",
    "    # shap.dependence_plot usually handles the plot creation, \n",
    "    # we pass 'ax' to tell it where to draw.\n",
    "    shap.dependence_plot(\n",
    "        col_name, \n",
    "        shap_values, \n",
    "        X, \n",
    "        ax=axes[i], \n",
    "        show=False, \n",
    "        interaction_index='auto' # Automatically picks the feature with strongest interaction to color by\n",
    "    )\n",
    "    axes[i].set_title(f\"SHAP: {col_name}\")\n",
    "\n",
    "# Hide any empty subplots if features don't fill the last row\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84269567",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(X.columns)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3*n_features, 3))\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    model, \n",
    "    X, \n",
    "    features=X.columns,  # Pass ALL columns here\n",
    "    ax=ax, \n",
    "    kind='average',\n",
    "    n_cols=n_features        # How many columns in the grid\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Partial Dependence Plots (All Features)\", y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_custom_pdp_easy(model, X, feat_x, feat_y, log_x=False, log_y=False):\n",
    "    \"\"\"\n",
    "    General PDP plotter using PartialDependenceDisplay.\n",
    "    feat_x: first feature (plotted on index 0 and as X in interaction)\n",
    "    feat_y: second feature (plotted on index 1 and as Y in interaction)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    pdp = PartialDependenceDisplay.from_estimator(\n",
    "        model, \n",
    "        X, \n",
    "        features=[\n",
    "            feat_x,\n",
    "            feat_y,\n",
    "            (feat_x, feat_y),\n",
    "        ],\n",
    "        ax=ax, \n",
    "        kind='average',\n",
    "    )\n",
    "\n",
    "    ax_inter = pdp.axes_[0, 2]\n",
    "    if log_x:\n",
    "        pdp.axes_[0, 0].set_xscale('log')\n",
    "        ax_inter.set_xscale('log')\n",
    "    if log_y:\n",
    "        pdp.axes_[0, 1].set_xscale('log')\n",
    "        ax_inter.set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_custom_pdp(model, X, feat_x, feat_y, log_x=False, log_y=False):\n",
    "    \"\"\"\n",
    "    Plots two 1D Partial Dependence plots and one 2D interaction heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "    - feat_x, feat_y: Strings of the feature names.\n",
    "    - log_x, log_y: Booleans to determine if the axis should be logarithmic.\n",
    "    \"\"\"\n",
    "    # 1. Calculate dependencies\n",
    "    pdp_x = partial_dependence(model, X, features=[feat_x], kind='average')\n",
    "    pdp_y = partial_dependence(model, X, features=[feat_y], kind='average')\n",
    "    pdp_inter = partial_dependence(model, X, features=[feat_x, feat_y], kind='average')\n",
    "\n",
    "    # 2. Setup Figure\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "\n",
    "    # --- Plot 1: feat_x (1D) ---\n",
    "    ax1.plot(pdp_x['grid_values'][0], pdp_x['average'][0])\n",
    "    ax1.set_xlabel(feat_x)\n",
    "    ax1.set_ylabel('Partial dependence')\n",
    "\n",
    "    # --- Plot 2: feat_y (1D) ---\n",
    "    ax2.plot(pdp_y['grid_values'][0], pdp_y['average'][0])\n",
    "    ax2.set_xlabel(feat_y)\n",
    "\n",
    "    # --- Plot 3: Interaction Heatmap (2D) ---\n",
    "    XX, YY = np.meshgrid(pdp_inter['grid_values'][0], pdp_inter['grid_values'][1])\n",
    "    Z = pdp_inter['average'][0].T\n",
    "    mesh = ax3.pcolormesh(XX, YY, Z, shading='auto', cmap='viridis')\n",
    "    ax3.set_xlabel(feat_x)\n",
    "    ax3.set_ylabel(feat_y)\n",
    "\n",
    "    cbar = fig.colorbar(mesh, ax=ax3)\n",
    "    cbar.set_label('Partial dependence')\n",
    "\n",
    "    if log_x:\n",
    "        ax1.set_xscale('log')\n",
    "        ax3.set_xscale('log')\n",
    "    \n",
    "    if log_y:\n",
    "        ax2.set_xscale('log')\n",
    "        ax3.set_yscale('log')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig, (ax1, ax2, ax3)\n",
    "\n",
    "plot_custom_pdp_easy(model, X, feat_x = 'hidden_dim', feat_y = 'num_features', log_x=True, log_y=False);\n",
    "plot_custom_pdp(model, X, feat_x = 'hidden_dim', feat_y = 'num_features', log_x=True, log_y=False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parallel = df_encoded.copy()\n",
    "\n",
    "bool_cols = df_parallel.select_dtypes(include=['bool']).columns\n",
    "for col in bool_cols:\n",
    "    df_parallel[col] = df_parallel[col].astype(int)\n",
    "\n",
    "fig = px.parallel_coordinates(\n",
    "    df_parallel, \n",
    "    color=\"density\",\n",
    "    color_continuous_scale=px.colors.sequential.Viridis,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff04e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_encoded.copy()\n",
    "\n",
    "# num_features_bins = np.linspace(0, 100, 6, endpoint=True)\n",
    "# hidden_dim_bins = np.linspace(0, 135, 6, endpoint=True)\n",
    "\n",
    "# assert df['num_features'].max() <= num_features_bins[-1], \"num_features exceeds the maximum bin limit\"\n",
    "# assert df['hidden_dim'].max() <= hidden_dim_bins[-1], \"hidden_dim exceeds the maximum bin limit\"\n",
    "\n",
    "# # Create categorical columns based on bins\n",
    "# df['num_features_bucket'] = pd.cut(df['num_features'], bins=num_features_bins, \n",
    "#                                      labels=[f'{num_features_bins[i]}-{num_features_bins[i+1]}' \n",
    "#                                             for i in range(len(num_features_bins)-1)])\n",
    "# df['hidden_dim_bucket'] = pd.cut(df['hidden_dim'], bins=hidden_dim_bins,\n",
    "#                                   labels=[f'{hidden_dim_bins[i]}-{hidden_dim_bins[i+1]}' \n",
    "#                                          for i in range(len(hidden_dim_bins)-1)])\n",
    "\n",
    "# num_features_buckets = df['num_features_bucket'].cat.categories\n",
    "# hidden_dim_buckets = df['hidden_dim_bucket'].cat.categories\n",
    "\n",
    "df['num_features_bucket'] = pd.qcut(df['num_features'], q=5, duplicates='drop', precision = 0)\n",
    "df['hidden_dim_bucket'] = pd.qcut(df['hidden_dim'], q=5, duplicates='drop', precision = 0)\n",
    "\n",
    "# Get the unique categories (Intervals) sorted\n",
    "num_features_buckets = sorted(df['num_features_bucket'].unique(), reverse=True)\n",
    "hidden_dim_buckets = sorted(df['hidden_dim_bucket'].unique())\n",
    "\n",
    "density_bins = np.linspace(0, 1, 11)\n",
    "\n",
    "figsize = 1.5\n",
    "nrows, ncols = len(num_features_buckets), len(hidden_dim_buckets)\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                        figsize=(figsize*ncols, figsize*nrows), \n",
    "                        squeeze=False, sharex=True, sharey=True)\n",
    "\n",
    "for i, num_features_bucket in enumerate(num_features_buckets):\n",
    "    for j, hidden_dim_bucket in enumerate(hidden_dim_buckets):\n",
    "        ax = axs[i, j]\n",
    "        \n",
    "        mask = (df['hidden_dim_bucket'] == hidden_dim_bucket) & \\\n",
    "               (df['num_features_bucket'] == num_features_bucket)\n",
    "        densities = df[mask]['density']\n",
    "        ax.hist(densities, bins=density_bins, alpha=0.7)\n",
    "        \n",
    "\n",
    "for j, hidden_dim_bucket in enumerate(hidden_dim_buckets):\n",
    "    hidden_dim_title = f'Hidden Dim\\n{hidden_dim_bucket}' if j == len(hidden_dim_buckets)//2 else f\"{hidden_dim_bucket}\"\n",
    "    ax = axs[0, j]\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.set_xlabel(hidden_dim_title, fontsize=10)\n",
    "\n",
    "for i, num_features_bucket in enumerate(num_features_buckets):\n",
    "    num_features_title = f'Num Feat\\n{num_features_bucket}' if i == len(num_features_buckets)//2 else f\"{num_features_bucket}\"\n",
    "    ax = axs[i, -1]\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.set_ylabel(num_features_title, fontsize=10, rotation = -90, va = 'bottom')\n",
    "\n",
    "\n",
    "fig.supxlabel('Density (% of possible edges)', y=0.02)\n",
    "fig.supylabel('Count', x=0.03, ha = 'center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# g = sns.FacetGrid(\n",
    "#     df, \n",
    "#     row=\"num_features_bucket\", \n",
    "#     col=\"hidden_dim_bucket\", \n",
    "#     row_order=num_features_buckets,\n",
    "#     col_order=hidden_dim_buckets,\n",
    "#     margin_titles=True,\n",
    "#     height=1.5,\n",
    "#     aspect=1.0, \n",
    "#     despine=False,\n",
    "# )\n",
    "\n",
    "# # 3. Map Histogram\n",
    "# density_bins = np.linspace(0, 1, 11)\n",
    "# g.map(plt.hist, \"density\", bins=density_bins, alpha=0.7)\n",
    "# g.set_axis_labels(\"\", \"\")\n",
    "# g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "\n",
    "# m = 0.90\n",
    "# g.fig.subplots_adjust(top=m, right=m)#, left=1-m, bottom=1-m)\n",
    "# g.fig.text(0.5, 0.96, 'Hidden Dim', ha='center', va='center', fontsize=11)\n",
    "# g.fig.text(0.98, 0.5, 'Num Feat', ha='center', va='center', rotation=-90, fontsize=11)\n",
    "\n",
    "# g.fig.supxlabel('Density (% of possible edges)', y=0.02)\n",
    "# g.fig.supylabel('Count', x=0.03, ha = 'center')\n",
    "\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
